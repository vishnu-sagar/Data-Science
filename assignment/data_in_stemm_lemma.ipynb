{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     D:\\Users\\sagarv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import os\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(o, tree_types=(list, tuple)):\n",
    "    if isinstance(o, tree_types):\n",
    "        for value in o:\n",
    "            for subvalue in traverse(value, tree_types):\n",
    "                yield subvalue\n",
    "    else:\n",
    "        yield o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "punct=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 1 columns):\n",
      "Comment    5 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 120.0+ bytes\n",
      "None\n",
      "COMPARING STEMMING AND LEMMATIZATION\n",
      "        STEMMING            LEMMATIZATION\n",
      "0       hello               Hello\n",
      "1       weather             Weather\n",
      "2       awesom              awesome\n",
      "3       it                  Its\n",
      "4       rain                raining\n",
      "5       hello               Hello\n",
      "6       mr.                 Mr.\n",
      "7       raja                Raja\n",
      "8       weather             Weather\n",
      "9       awesom              awesome\n",
      "10      it                  Its\n",
      "11      rain                raining\n",
      "12      hello               Hello\n",
      "13      mr.                 Mr.\n",
      "14      raja                Raja\n",
      "15      weather             Weather\n",
      "16      bad                 bad\n",
      "17      it                  Its\n",
      "18      heavili             heavily\n",
      "19      rain                raining\n",
      "20      nlp                 NLP\n",
      "21      great               great\n",
      "22      techniqu            technique\n",
      "23      It                  It\n",
      "24      nice                nice\n",
      "25      learn               learn\n",
      "26      techniqu            technique\n",
      "27      AI                  AI\n",
      "28      make                making\n",
      "29      differ              difference\n",
      "30      world               world\n",
      "31      It                  It\n",
      "32      would               would\n",
      "33      help                helpful\n",
      "34      better              betterment\n",
      "35      human               human\n",
      "36      life                life\n",
      "37      We                  We\n",
      "38      need                need\n",
      "39      make                make\n",
      "40      advantag            advantage\n"
     ]
    }
   ],
   "source": [
    "dir=r\"D:\\Users\\sagarv\\Desktop\\Inputfiles\"\n",
    "text=pd.read_csv(os.path.join(dir,\"NLPdataEx3&4-data_in.txt\"),sep='\\t',names=['Comment'])\n",
    "print(text.info())\n",
    "\n",
    "\n",
    "word_token=[]\n",
    "for n in text['Comment']:\n",
    "    word_token.append(word_tokenize(n))\n",
    "    \n",
    "my_words=list(traverse(word_token))\n",
    "    \n",
    "words = [ word for word in my_words if word not in punct]\n",
    "\n",
    "words_clean = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "    \n",
    "\n",
    "word_stem=[]\n",
    "ps=PorterStemmer()\n",
    "for w in words_clean:\n",
    "    word_stem.append(ps.stem(w))\n",
    "    \n",
    "    \n",
    "word_lemma=[]\n",
    "lm=WordNetLemmatizer()\n",
    "for x in words_clean:\n",
    "    word_lemma.append(lm.lemmatize(x))\n",
    "    \n",
    "    \n",
    "    \n",
    "fmt = '{:<8}{:<20}{}'\n",
    "\n",
    "print(\"COMPARING STEMMING AND LEMMATIZATION\")\n",
    "print(fmt.format('', 'STEMMING', 'LEMMATIZATION'))\n",
    "for i, (x, n) in enumerate(zip(word_stem, word_lemma)):\n",
    "    print(fmt.format(i, x, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
